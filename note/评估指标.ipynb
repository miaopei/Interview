{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评估指标\n",
    "\n",
    "## 1. 分类和回归\n",
    "\n",
    "分类涉及到根据未见过的样本进行预测，并确定新实例属于哪个类别。例如，可以根据蓝色或红色或者方形或圆形来组织对象，以便在看到新对象时根据其特征来组织对象。\n",
    "\n",
    "在回归中，我们想根据连续数据来进行预测。例如，我们有包含不同人员的身高、年龄和性别的列表，并想预测他们的体重。或者，像在本课程的最终项目中一样，我们可能有一些房屋数据，并想预测某所住宅的价值。\n",
    "\n",
    "手头的问题在很大程度上决定着我们如何评估模型。\n",
    "\n",
    "## 2. 分类指标和回归指标\n",
    "\n",
    "在分类中，我们想了解模型隔多久正确或不正确地识别新样本一次。而在回归中，我们可能更关注模型的预测值与真正值之间差多少。\n",
    "\n",
    "在本节课的余下部分，我们会探讨几个性能指标。对于分类，我们会探讨准确率、精确率、召回率和 F1 分数。对于回归，我们会探讨平均绝对误差和均方误差。\n",
    "\n",
    "## 3. 分类指标\n",
    "\n",
    "对于分类，我们处理的是根据离散数据进行预测的模型。这就是说，此类模型确定新实例是否属于给定的一组类别。在这里，我们测量预测是否准确地将所讨论的实例进行分类。\n",
    "\n",
    "现在我先假定一个具体场景作为例子：\n",
    "\n",
    "> 假如某个班级有男生80人,女生20人,共计100人.目标是找出所有女生.\n",
    "\n",
    "> 现在某人挑选出50个人,其中20人是女生,另外还错误的把30个男生也当作女生挑选出来了.\n",
    "\n",
    "> 作为评估者的你需要来评估(evaluation)下他的工作\n",
    "\n",
    "将挑选结果用 矩阵示意表来表示 ： 定义TP,FN,FP,TN四种分类情况\n",
    "\n",
    "| |相关(Relevant),正类 | 无关(NonRelevant),负类 |\n",
    "| -- | -- | -- |\n",
    "| 被检索到(Retrieved) | TP 系统检索到的相关文档,例\"其中20人是女生\" | FP 系统检索到的不相关文档,例”错误把30个男生当女生“ |\n",
    "| 未被检索到(Not Retrieved) | FN 相关系统未检索到的文档,例\"未挑0人是女生\" | TN 相关但是系统没有检索到的文档,例”未挑50人非女生“ |\n",
    "\n",
    "### 3.1 准确率\n",
    "\n",
    "准确率实际上是所有被正确标示的数据点除以所有的数据点。如果你是在看特定类的表现，我们需要看召回率（recall），这在后面的课程中会讲到。\n",
    "\n",
    "准确率(accuracy)的公式是：\n",
    "\n",
    "$$A = \\frac{TP+TN}{TP+FP+FN+TN}$$\n",
    "\n",
    "其定义是: 对于给定的测试数据集，分类器正确分类的样本数与总样本数之比。也就是损失函数是0-1损失时测试数据集上的准确率\n",
    "\n",
    "$$A = \\frac{20 + 50}{100} = 70%$$\n",
    "\n",
    "### 3.2 精确率\n",
    "\n",
    "精确率(precision)的公式是：\n",
    "\n",
    "$$P = \\frac{TP}{TP+FP}$$\n",
    "\n",
    "它计算的是所有被检索到的item中,\"应该被检索到\"的item占的比例。\n",
    "\n",
    "$$P = \\frac{20}{20+30} = 40%$$\n",
    "\n",
    "### 3.3 召回率\n",
    "\n",
    "召回率(recall)的公式是：\n",
    "\n",
    "$$R = \\frac{TP}{TP+FN}$$\n",
    "\n",
    "它计算的是所有检索到的item占所有\"应该检索到的item\"的比例。\n",
    "\n",
    "$$R = \\frac{20}{20 + 0} = 100%$$\n",
    "\n",
    "### 3.4 F1 分数\n",
    "\n",
    "既然我们已讨论了精确率和召回率，接下来可能要考虑的另一个指标是 F1 分数。F1 分数会同时考虑精确率和召回率，以便计算新的分数。\n",
    "\n",
    "可将 F1 分数理解为精确率和召回率的加权平均值，其中 F1 分数的最佳值为 1、最差值为 0：\n",
    "\n",
    "$$F1 = \\frac{2 * 精确率 * 召回率}{ 精确率 + 召回率 }$$\n",
    "\n",
    "$P$ 和 $R$ 指标有的时候是矛盾的,综合考虑精确率(precision)和召回率(recall)这两个度量值。很容易理解，$F1$ 综合了 $P$ 和 $R$ 的结果，当 $F1$ 较高时则比较说明实验方法比较理想。\n",
    "\n",
    "$$F1 = \\frac{2 * 0.4 * 1}{0.4 + 1} = 57%$$\n",
    "\n",
    "[sklearn F1分数](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score)\n",
    "\n",
    "\n",
    "## 4. 回归指标\n",
    "\n",
    "正如前面对问题的回归类型所做的介绍，我们处理的是根据连续数据进行预测的模型。在这里，我们更关注预测的接近程度。\n",
    "\n",
    "例如，对于身高和体重预测，我们不是很关心模型能否将某人的体重 100% 准确地预测到小于零点几磅，但可能很关心模型如何能始终进行接近的预测（可能与个人的真实体重相差 3-4 磅）。\n",
    "\n",
    "### 4.1 平均绝对误差\n",
    "\n",
    "您可能已回想起，在统计学中可以使用绝对误差来测量误差，以找出预测值与真实值之间的差距。平均绝对误差的计算方法是，将各个样本的绝对误差汇总，然后根据数据点数量求出平均误差。通过将模型的所有绝对值加起来，可以避免因预测值比真实值过高或过低而抵销误差，并能获得用于评估模型的整体误差指标。\n",
    "\n",
    "[sklearn 平均绝对误差](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error)\n",
    "\n",
    "### 4.2 均方误差\n",
    "\n",
    "均方误差是另一个经常用于测量模型性能的指标。与绝对误差相比，残差（预测值与真实值的差值）被求平方。\n",
    "\n",
    "对残差求平方的一些好处是，自动将所有误差转换为正数、注重较大的误差而不是较小的误差以及在微积分中是可微的（可让我们找到最小值和最大值）。\n",
    "\n",
    "[sklearn 均方误差](https://classroom.udacity.com/nanodegrees/nd009-cn-advanced/parts/5cccb7ec-1b3f-4725-8480-c94509df0a1f/modules/f3aed286-c5da-4df6-95de-56a5301b8938/lessons/5453289163/concepts/55005792430923)\n",
    "\n",
    "### 4.3 回归分数函数\n",
    "\n",
    "除了误差指标之外，scikit-learn还包括了两个分数指标，范围通常从0到1，值0为坏，而值1为最好的表现，看起来和分类指标类似，都是数字越接近1.0分数就越好。\n",
    "\n",
    "其中之一是 [R2分数](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score)，用来计算真值预测的可决系数。在 scikit-learn 里，这也是回归学习器默认的分数方法。\n",
    "\n",
    "另一个是[可释方差分数](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score)\n",
    "\n",
    "虽然眼下我们不会详细探讨这些指标，一个要记住的重点是，回归的默认指标是“分数越高越好”；即，越高的分数表明越好的表现。而当我们用到前面讲的误差指标时，我们要改变这个设定。\n",
    "\n",
    "## 5. 误差原因\n",
    "\n",
    "我们已讨论了一些用于测量模型性能的基本指标，现在来关注一下模型起初为何会出现误差。\n",
    "\n",
    "在模型预测中，模型可能出现的误差来自两个主要来源，即：因模型无法表示基本数据的复杂度而造成的偏差（bias），或者因模型对训练它所用的有限数据过度敏感而造成的方差（variance）。我们会对两者进行更详细的探讨。\n",
    "\n",
    "## 6. 偏差造成的误差 - 准确率和欠拟合\n",
    "\n",
    "如前所述，如果模型具有足够的数据，但因不够复杂而无法捕捉基本关系，则会出现偏差。这样一来，模型一直会系统地错误表示数据，从而导致准确率降低。这种现象叫做欠拟合（underfitting）。\n",
    "\n",
    "简单来说，如果模型不适当，就会出现偏差。举个例子：如果对象是按颜色和形状分类的，但模型只能按颜色来区分对象和将对象分类（模型过度简化），因而一直会错误地分类对象。\n",
    "\n",
    "或者，我们可能有本质上是多项式的连续数据，但模型只能表示线性关系。在此情况下，我们向模型提供多少数据并不重要，因为模型根本无法表示其中的基本关系，我们需要更复杂的模型。\n",
    "\n",
    "## 7. 方差造成的误差 - 精度和过拟合\n",
    "\n",
    "在训练模型时，通常使用来自较大训练集的有限数量样本。如果利用随机选择的数据子集反复训练模型，可以预料它的预测结果会因提供给它的具体样本而异。在这里，方差（variance）用来测量预测结果对于任何给定的测试样本会出现多大的变化。\n",
    "\n",
    "出现方差是正常的，但方差过高表明模型无法将其预测结果泛化到更多的数据。对训练集高度敏感也称为过拟合（overfitting），而且通常出现在模型过于复杂或我们没有足够的数据支持它时。\n",
    "\n",
    "通常，可以利用更多数据进行训练，以降低模型预测结果的方差并提高精度。如果没有更多的数据可以用于训练，还可以通过限制模型的复杂度来降低方差。\n",
    "\n",
    "## 8. 学习曲线\n",
    "\n",
    "现在你理解了偏差和方差的概念，让我们学习一下如何辨别模型表现的好坏。sklearn中的学习曲线函数可以帮到我们。它可以让我们通过数据点来了解模型表现的好坏。\n",
    "\n",
    "可以先引入这个模块\n",
    "\n",
    "    from sklearn.learning_curve import learning_curve # sklearn 0.17\n",
    "    from sklearn.model_selection import learning_curve # sklearn 0.18\n",
    "\n",
    "文档中一个合理的实现是：\n",
    "\n",
    "    learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "        \n",
    "这里estimator是我们正在用来预测的模型，例如它可以是GaussianNB()，X和y是特征和目标。cv是交叉验证生成器，例如KFold()，'n_jobs'是平行运算的参数，train_sizes是多少数量的训练数据用来生成曲线。\n",
    "\n",
    "在接下来的练习中，您将为我们的模型定义学习曲线，并观察其效果。\n",
    "\n",
    "让我们根据模型通过可视化图形从数据中学习的能力来探讨偏差与方差之间的关系。\n",
    "\n",
    "机器学习中的学习曲线是一种可视化图形，能根据一系列训练实例中的训练和测试数据比较模型的指标性能。\n",
    "\n",
    "在查看数据与误差之间的关系时，我们通常会看到，随着训练点数量的增加，误差会趋于下降。由于我们尝试构建从经验中学习的模型，因此这很有意义。\n",
    "\n",
    "我们将训练集和测试集分隔开，以便更好地了解能否将模型泛化到未见过的数据而不是拟合到刚见过的数据。\n",
    "\n",
    "在学习曲线中，当训练曲线和测试曲线均达到稳定阶段，并且两者之间的差距不再变化时，则可以确认模型已尽其所能地了解数据。\n",
    "\n",
    "### 8.1 偏差\n",
    "\n",
    "在训练误差和测试误差收敛并且相当高时，这实质上表示模型具有偏差。无论我们向其提供多少数据，模型都无法表示基本关系，因而出现系统性的高误差。\n",
    "\n",
    "### 8.2 方差\n",
    "\n",
    "如果训练误差与测试误差之间的差距很大，这实质上表示模型具有高方差。与偏差模型不同的是，如果有更多可供学习的数据，或者能简化表示数据的最重要特征的模型，则通常可以改进具有方差的模型。\n",
    "\n",
    "### 8.3 理想的学习曲线\n",
    "\n",
    "模型的最终目标是，误差小并能很好地泛化到未见过的数据（测试数据）。如果测试曲线和训练曲线均收敛，并且误差极低，就能看到这种模型。这种模型能根据未见过的数据非常准确地进行预测。\n",
    "\n",
    "## 9. 模型复杂度\n",
    "\n",
    "与学习曲线图形不同，模型复杂度图形呈现的是模型复杂度如何改变训练曲线和测试曲线，而不是呈现用来训练模型的数据点数量。一般趋势是，随着模型增大，模型对固定的一组数据表现出更高的变化性。\n",
    "\n",
    "### 9.1 模型复杂度的实际使用\n",
    "\n",
    "既然知道了能通过分析模型复杂度图形来识别偏差和方差的问题，现在可利用一个可视化工具来帮助找出优化模型的方法。在下一部分中，我们会探讨 gridsearch 和如何微调模型以获得更好的性能。\n",
    "\n",
    "## 10. 摘要\n",
    "\n",
    "小结：我们回顾了一些基本的统计学概念，还研究了几个指标，以根据手头的问题评估模型的学习表现。\n",
    "\n",
    "接着，我们探讨了几种数据类型和分解数据的方式，以验证模型是否确实进行学习以泛化到未见过的数据，而不是泛化到给定的训练集。\n",
    "\n",
    "然后，我们研究了模型可能会出现的两种常见误差：因未充分表示或欠拟合基本数据和方差而造成的偏差；以及过拟合训练数据且不再能很好泛化的模型复杂度。\n",
    "\n",
    "最后，我们研究了模型复杂度，并使用了 gridsearch 来识别模型的最佳参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
